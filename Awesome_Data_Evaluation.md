# Awesome Data Evaluation
## Table of Contents
- [Awesome Data Evaluation](#Awesome-Data-Evaluation)
  - [Pure Text Evaluation](#Pure-Text-Evaluation)
  - [Image Data Quality Evaluation](#Image-Data-Quality-Evaluation)
    - [Synthetic Image Evaluation](#Synthetic-Image-Evaluation)
    - [Pure Image Evaluation](#Pure-Image-Evaluation)
    - [Image-Caption Evaluation](#Image-Caption-Evaluation)
  - [Video Data Quality Evaluation](#Video-Data-Quality-Evaluation)
    - [Pure Video Evaluation](#Pure-Video-Evaluation)
    - [Video-Caption Evaluation](#Video-Caption-Evaluation)
  - [Data Diversity Evaluation](#Data-Diversity-Evaluation)
# Pure Text Evaluation
### Text Evaluation Taxonomy:
1. Text Structure
2. Diversity & Complexity
3. Fluency & Understandability
4. Safety
5. Educational Value
6. Content Accuracy & Effectiveness

| Title                                                                                                                                                                                                                                                                         |     Venue     |    Date    |                                                  Code                                                  | Taxonomy                         |
| :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----------: | :--------: | :----------------------------------------------------------------------------------------------------: | -------------------------------- |
| [**AlpaGasus: Training A Better Alpaca with Fewer Data**](https://arxiv.org/abs/2307.08701)                                                                                                                                                                                   |     Arxiv     | 2023.07.17 |                                         [Github](./README.md)                                          | Content Accuracy & Effectiveness |
| [**A Preliminary Study of the Intrinsic Relationship between Complexity and Alignment**](https://arxiv.org/abs/2308.05696)                                                                                                                                                    |     Arxiv     | 2023.08.10 |                                         [Github](./README.md)                                          | Diversity & Complexity           |
| ![Star](https://img.shields.io/github/stars/alycialee/beyond-scale-language-data-diversity.svg?style=social&label=Star)<br>[**Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data**](https://arxiv.org/abs/2306.13840)  | ICLR Workshop | 2023.06.24 |              [Github](https://github.com/alycialee/beyond-scale-language-data-diversity)               | Content Accuracy & Effectiveness |
| ![Star](https://img.shields.io/github/stars/huggingface/cosmopedia.svg?style=social&label=Star)<br>[**The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale**](https://arxiv.org/abs/2406.17557)                                                          |     Arxiv     | 2024.06.25 |               [Huggingface](https://huggingface.co/HuggingFaceFW/fineweb-edu-classifier)               | Educational Value                |
| ![Star](https://img.shields.io/github/stars/OFA-Sys/InsTag.svg?style=social&label=Star)<br>[**# InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models**](https://openreview.net/pdf?id=pszewhybU9)                                        |     ICLR      |    2023    | [Github](https://github.com/OFA-Sys/InsTag)<br>[Huggingface](https://huggingface.co/OFA-Sys/InsTagger) | Diversity & Complexity           |
| ![Star](https://img.shields.io/github/stars/kpu/kenlm.svg?style=social&label=Star)<br>[**KenLM: Faster and Smaller Language Model Queries**](https://aclanthology.org/W11-2123.pdf)                                                                                           |      ACL      |    2011    | [Github](https://github.com/kpu/kenlm)<br>[Huggingface](https://huggingface.co/edugp/kenlm/tree/main)  | Fluency & Understandability      |
| ![Star](https://img.shields.io/github/stars/princeton-nlp/QuRating.svg?style=social&label=Star)<br>[**QuRating: Selecting High-Quality Data for Training Language Models**](https://arxiv.org/abs/2402.09739)                                                                 |     ICML      |    2024    |                          [Github](https://github.com/princeton-nlp/QuRating)                           | Fluency & Understandability      |
| ![Star](https://img.shields.io/github/stars/tianyi-lab/Superfiltering.svg?style=social&label=Star)<br>[**Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning**](https://arxiv.org/abs/2402.00530)                                                       |     Arxiv     | 2024.02.01 |                         [Github](https://github.com/tianyi-lab/Superfiltering)                         | Fluency & Understandability      |
| ![Star](https://img.shields.io/github/stars/kyegomez/phi-1.svg?style=social&label=Star)<br>[**Textbooks Are All You Need**](https://arxiv.org/abs/2402.09739)                                                                                                                 |     Arxiv     | 2023.06.20 |                              [Github](https://github.com/kyegomez/phi-1)                               | Educational Value                |
| ![Star](https://img.shields.io/github/stars/maszhongming/UniEval.svg?style=social&label=Star)<br>[**Towards a Unified Multi-Dimensional Evaluator for Text Generation**](https://arxiv.org/abs/2210.07197)                                                                    |     Arxiv     | 2022.10.13 |                           [Github](https://github.com/maszhongming/UniEval)                            | Fluency & Understandability      |
| ![Star](https://img.shields.io/github/stars/hkust-nlp/deita.svg?style=social&label=Star)<br>[**What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning**](https://arxiv.org/abs/2312.15685)                               |     Arxiv     | 2023.12.25 |                              [Github](https://github.com/hkust-nlp/deita)                              | Content Accuracy & Effectiveness |
| ![Star](https://img.shields.io/github/stars/jennafrens/lexical_diversity.svg?style=social&label=Star)<br>[**MTLD, vocd-D, and HD-D: A validation study of sophisticated approaches to lexical diversity assessment**](https://link.springer.com/article/10.3758/BRM.42.2.381) |   Springer    |    2010    |                 [Github](https://github.com/jennafrens/lexical_diversity/tree/master)                  | Diversity & Complexity           |

# Image Data Quality Evaluation
## Synthetic Image Evaluation
### Synthetic Image Evaluation Taxonomy:
1. Metric Based Evaluation
2. Benchmarks

| Title                                                                                                                                                                                                                                    |      Venue       |    Date    |                                     Code                                     | Taxonomy                |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------: | :--------: | :--------------------------------------------------------------------------: | ----------------------- |
| ![Star](https://img.shields.io/github/stars/abdulfatir/gan-metrics-pytorch.svg?style=social&label=Star)<br>[**FID Score**](https://arxiv.org/abs/1706.08500)                                                                             |     Neurips      |    2017    |              [Github](https://github.com/mseitzer/pytorch-fid)               | Metric Based Evaluation |
| ![Star](https://img.shields.io/github/stars/abdulfatir/gan-metrics-pytorch.svg?style=social&label=Star)<br>[**KID Score**](https://arxiv.org/abs/1801.01401)                                                                             |      Arxiv       | 2018.01.04 |         [Github](https://github.com/abdulfatir/gan-metrics-pytorch)          | Metric Based Evaluation |
| ![Star](https://img.shields.io/github/stars/mseitzer/pytorch-fid.svg?style=social&label=Star)<br>[**FID Score**](https://arxiv.org/abs/1606.03498)                                                                                       |     Neurips      |    2016    |              [Github](https://github.com/mseitzer/pytorch-fid)               | Metric Based Evaluation |
| [**AIGIQA-20K: A Large Database for AI-Generated Image Quality Assessment**](https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/papers/Li_AIGIQA-20K_A_Large_Database_for_AI-Generated_Image_Quality_Assessment_CVPRW_2024_paper.pdf) | CVPR<br>Workshop |    2024    | [ModelScope](https://www.modelscope.cn/datasets/lcysyzxdxc/AIGCQA-30K-Image) | Benchmarks              |

## Pure Image Evaluation
### Pure Image Evaluation Taxonomy:
1. Statistical Metric Based Evaluation (Statistics)
2. Neural Network Based Evaluation (NN)
3. Pre-trained Model Based Evaluation (Pre-train)

| Title                                                                                                                                                                                                                                                                                                                                                                      | Venue |    Date    |                                                                         Code                                                                         | Taxonomy   |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--------: | :--------------------------------------------------------------------------------------------------------------------------------------------------: | ---------- |
| ![Star](https://img.shields.io/github/stars/krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model.svg?style=social&label=Star)<br>[**No-Reference Image Quality Assessment in the Spatial Domain**](https://ieeexplore.ieee.org/abstract/document/6272356)                                                                                                  |  TIP  |    2012    | [Github](https://github.com/krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model)<br>[Zhihu](https://zhuanlan.zhihu.com/p/147005796) | Statistics |
| ![Star](https://img.shields.io/github/stars/yunxiaoshi/Neural-IMage-Assessment.svg?style=social&label=Star)<br>[**NIMA: Neural Image Assessment**](https://ieeexplore.ieee.org/abstract/document/8352823)                                                                                                                                                                  |  TIP  |    2018    |                                           [Github](https://github.com/yunxiaoshi/Neural-IMage-Assessment)                                            | NN         |
| ![Star](https://img.shields.io/github/stars/anse3832/MUSIQ.svg?style=social&label=Star)<br>[**MUSIQ: Multi-scale Image Quality Transformer**](http://openaccess.thecvf.com/content/ICCV2021/papers/Ke_MUSIQ_Multi-Scale_Image_Quality_Transformer_ICCV_2021_paper.pdf)                                                                                                     | ICCV  |    2021    |                                                     [Github](https://github.com/anse3832/MUSIQ)                                                      | NN         |
| ![Star](https://img.shields.io/github/stars/chaofengc/iqa-pytorch.svg?style=social&label=Star)<br>[**TOPIQ: A Top-down Approach from Semantics to Distortions for Image Quality Assessment**](https://ieeexplore.ieee.org/abstract/document/10478301)                                                                                                                      |  TIP  |    2024    |                                                  [Github](https://github.com/chaofengc/iqa-pytorch)                                                  | NN         |
| [**Local Distortion Aware Efficient Transformer Adaptation for Image Quality Assessment**](https://arxiv.org/abs/2308.12001)                                                                                                                                                                                                                                               | Arxiv | 2023.08.23 |                                                                          -                                                                           | NN         |
| [**Quality-Aware Pre-Trained Models for Blind Image Quality Assessment**](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Quality-Aware_Pre-Trained_Models_for_Blind_Image_Quality_Assessment_CVPR_2023_paper.pdf)                                                                                                                                              | CVPR  |    2023    |                                                                          -                                                                           | Pre-train  |
| ![Star](https://img.shields.io/github/stars/IceClear/CLIP-IQA.svg?style=social&label=Star)<br>[**Exploring CLIP for Assessing the Look and Feel of Images**](https://ojs.aaai.org/index.php/AAAI/article/view/25353/25125)                                                                                                                                                 | AAAI  |    2023    |                                                    [Github](https://github.com/IceClear/CLIP-IQA)                                                    | Pre-train  |
| ![Star](https://img.shields.io/github/stars/miccunifi/QualiCLIP.svg?style=social&label=Star)<br>[**Quality-Aware Image-Text Alignment for Real-World Image Quality Assessment**](https://arxiv.org/abs/2403.11176)                                                                                                                                                         | Arxiv | 2024.03.17 |                                                   [Github](https://github.com/miccunifi/QualiCLIP)                                                   | Pre-train  |
| ![Star](https://img.shields.io/github/stars/tgxs002/align_sd.svg?style=social&label=Star)<br>[**Human Preference Score: Better Aligning Text-to-Image Models with Human Preference**](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Human_Preference_Score_Better_Aligning_Text-to-Image_Models_with_Human_Preference_ICCV_2023_paper.pdf)                      | ICCV  |    2023    |                                                    [Github](https://github.com/tgxs002/align_sd)                                                     | Pre-train  |
| ![Star](https://img.shields.io/github/stars/zwx8981/LIQE.svg?style=social&label=Star)<br>[**Blind Image Quality Assessment via Vision-Language Correspondence: A Multitask Learning Perspective**](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Blind_Image_Quality_Assessment_via_Vision-Language_Correspondence_A_Multitask_Learning_CVPR_2023_paper.pdf) | CVPR  |    2023    |                                                      [Github](https://github.com/zwx8981/LIQE)                                                       | Pre-train  |

## Image-Caption Evaluation
### Image-Caption Evaluation Taxonomy:
1. CLIP Based (CLIP)
2. Large Language Model Based (LLM)
3. Vision Large Language Model Based (VLLM)

| Title                                                                                                                                                                                                                                                                                                                                                        |  Venue  |    Date    |                              Code                               | Taxonomy   |
| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-----: | :--------: | :-------------------------------------------------------------: | ---------- |
| ![Star](https://img.shields.io/github/stars/jmhessel/clipscore.svg?style=social&label=Star)<br>[**CLIPScore: A Reference-free Evaluation Metric for Image Captioning**](https://arxiv.org/abs/2104.08718)                                                                                                                                                    |  Arxiv  | 2021.04.18 |         [Github](https://github.com/jmhessel/clipscore)         | CLIP       |
| ![Star](https://img.shields.io/github/stars/Yebin46/FLEUR.svg?style=social&label=Star)<br>[**FLEUR: An Explainable Reference-Free Evaluation Metric for Image Captioning Using a Large Multimodal Modelt**](https://arxiv.org/abs/2406.06004)                                                                                                                |   ACL   |    2024    |           [Github](https://github.com/Yebin46/FLEUR)            | VLLM       |
| ![Star](https://img.shields.io/github/stars/linzhiqiu/t2v_metrics.svg?style=social&label=Star)<br>[**Evaluating Text-to-Visual Generation with Image-to-Text Generation**](https://arxiv.org/abs/2404.01291)                                                                                                                                                 |  Arxiv  | 2024.04.01 |       [Github](https://github.com/linzhiqiu/t2v_metrics)        | VLLM       |
| ![Star](https://img.shields.io/github/stars/HAWLYQ/InfoMetIC.svg?style=social&label=Star)<br>[**InfoMetIC: An Informative Metric for Reference-free Image Caption Evaluation**](https://arxiv.org/pdf/2305.06002)                                                                                                                                            |  Arxiv  | 2023.05.10 |          [Github](https://github.com/HAWLYQ/InfoMetIC)          | CLIP       |
| ![Star](https://img.shields.io/github/stars/joeyz0z/HICE.svg?style=social&label=Star)<br>[**HICEScore: A Hierarchical Metric for Image Captioning Evaluation**](https://arxiv.org/abs/2407.18589)                                                                                                                                                            |  Arxiv  | 2024.07.26 |            [Github](https://github.com/joeyz0z/HICE)            | CLIP       |
| ![Star](https://img.shields.io/github/stars/YujieLu10/LLMScore.svg?style=social&label=Star)<br>[**LLMScore: Unveiling the Power of Large Language Models in Text-to-Image Synthesis Evaluation**](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Exploring_Video_Quality_Assessment_on_User_Generated_Contents_from_Aesthetic_ICCV_2023_paper.pdf) | Neurips |    2024    |         [Github](https://github.com/YujieLu10/LLMScore)         | LLM        |
| ![Star](https://img.shields.io/github/stars/1jsingh/Divide-Evaluate-and-Refine.svg?style=social&label=Star)<br>[**Divide, Evaluate, and Refine: Evaluating and Improving Text-to-Image Alignment with Iterative VQA Feedback**](https://proceedings.neurips.cc/paper_files/paper/2023/file/dfd0bd56e8a6f82d1619f5d093d5f9ca-Paper-Conference.pdf)            | Neurips |    2023    | [Github](https://github.com/1jsingh/Divide-Evaluate-and-Refine) | VLLM, CLIP |

# Video Data Quality Evaluation
## Pure Video Evaluation
### Pure Video Evaluation Taxonomy:
1. Statistical Metric Based (Statistics)
2. Neural Network Based (NN)

| Title                                                                                                                                                                                                                                                                                                                                                                   | Venue |    Date    |                                                              Code                                                               | Taxonomy   |
| :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--------: | :-----------------------------------------------------------------------------------------------------------------------------: | ---------- |
| [**Perceptual Video Quality Assessment: A Survey**](https://arxiv.org/abs/2402.03413)                                                                                                                                                                                                                                                                                   | Arxiv | 2024.02.05 |                                                                -                                                                | Survey     |
| ![Star](https://img.shields.io/github/stars/jarikorhonen/nr-vqa-consumervideo.svg?style=social&label=Star)<br>[**Two-Level Approach for No-Reference Consumer Video Quality Assessment**](https://ieeexplore.ieee.org/abstract/document/8742797)                                                                                                                        |  TIP  |    2019    | [Github](https://github.com/jarikorhonen/nr-vqa-consumervideo)<br>[Github(Improved)](https://github.com/jarikorhonen/cnn-tlvqm) | Statistics |
| ![Star](https://img.shields.io/github/stars/vztu/VIDEVAL.svg?style=social&label=Star)<br>[**UGC-VQA: Benchmarking blind video quality assessment for user generated content**](https://ieeexplore.ieee.org/abstract/document/9405420)                                                                                                                                   |  TIP  |    2021    |                                            [Github](https://github.com/vztu/VIDEVAL)                                            | Statistics |
| ![Star](https://img.shields.io/github/stars/VQAssessment/FAST-VQA-and-FasterVQA.svg?style=social&label=Star)<br>[**FAST-VQA: Efficient End-to-end Video Quality Assessment with Fragment Sampling**](https://link.springer.com/chapter/10.1007/978-3-031-20068-7_31)                                                                                                    | ECCV  |    2022    |                                [Github](https://github.com/VQAssessment/FAST-VQA-and-FasterVQA)                                 | NN         |
| ![Star](https://img.shields.io/github/stars/VQAssessment/FAST-VQA-and-FasterVQA.svg?style=social&label=Star)<br>[**Neighbourhood Representative Sampling for Efficient End-to-End Video Quality Assessment**](https://ieeexplore.ieee.org/abstract/document/10264158)                                                                                                   | TPAMI |    2023    |                                [Github](https://github.com/VQAssessment/FAST-VQA-and-FasterVQA)                                 | NN         |
| ![Star](https://img.shields.io/github/stars/VQAssessment/DOVER.svg?style=social&label=Star)<br>[**Exploring Video Quality Assessment on User Generated Contents from Aesthetic and Technical Perspectives**](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Exploring_Video_Quality_Assessment_on_User_Generated_Contents_from_Aesthetic_ICCV_2023_paper.pdf) | ICCV  |    2023    |                                         [Github](https://github.com/VQAssessment/DOVER)                                         | NN         |

## Video-Caption Evaluation

| Title                                                                                                                                                                                                                                                                                                                                                                  | Venue | Date |                      Code                       | Taxonomy |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--: | :---------------------------------------------: | -------- |
| ![Star](https://img.shields.io/github/stars/ShiYaya/emscore.svg?style=social&label=Star)<br>[**EMScore: Evaluating Video Captioning via Coarse-Grained and Fine-Grained Embedding Matching**](http://openaccess.thecvf.com/content/CVPR2022/papers/Shi_EMScore_Evaluating_Video_Captioning_via_Coarse-Grained_and_Fine-Grained_Embedding_Matching_CVPR_2022_paper.pdf) | CVPR  | 2022 |  [Github](https://github.com/shiyaya/emscore)   | CLIP     |
| ![Star](https://img.shields.io/github/stars/aimagelab/pacscore.svg?style=social&label=Star)<br>[**Positive-Augmented Contrastive Learning for Image and Video Captioning Evaluation**](https://openaccess.thecvf.com/content/CVPR2023/papers/Sarto_Positive-Augmented_Contrastive_Learning_for_Image_and_Video_Captioning_Evaluation_CVPR_2023_paper.pdf)              | CVPR  | 2023 | [Github](https://github.com/aimagelab/pacscore) | CLIP     |


# Data Diversity Evaluation
| Title                                                                                                                                                                                                                                            | Venue |    Date    |                                    Code                                     |
| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---: | :--------: | :-------------------------------------------------------------------------: |
| ![Star](https://img.shields.io/github/stars/vertaix/Vendi-Score.svg?style=social&label=Star)<br>[**The Vendi Score: A Diversity Evaluation Metric for Machine Learning**](https://par.nsf.gov/servlets/purl/10427561)                            | TMLR  |    2023    |              [Github](https://github.com/vertaix/Vendi-Score)               |
| ![Star](https://img.shields.io/github/stars/vertaix/Quality-Weighted-Vendi-Score.svg?style=social&label=Star)<br>[**Quality-Weighted Vendi Scores and Their Application to Diverse Experimental Design**](https://arxiv.org/pdf/2405.02449)      | ICML  |    2024    |      [Github](https://github.com/vertaix/Quality-Weighted-Vendi-Score)      |
| ![Star](https://img.shields.io/github/stars/aimagelab/pacscore.svg?style=social&label=Star)<br>[**Beyond Scale: The Diversity Coefficient as a Data Quality Metric for Variability in Natural Language Data**](https://arxiv.org/pdf/2306.13840) | Arxiv | 2023.06.24 | [Github](https://github.com/alycialee/beyond-scale-language-data-diversity) |
